{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"000_shared.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "class FUtilz:\n",
    "    ## ===== aggregators \n",
    "    @staticmethod\n",
    "    def identity(x):\n",
    "        return x\n",
    "    @staticmethod \n",
    "    def linear(x,w,b):\n",
    "        #print(\"linear inputs:\", np.round(x,3), np.round(w,4), np.round(b,4) )\n",
    "        xo = np.dot(w.T, x)+b\n",
    "        #print(\"Z: \", xo)\n",
    "        return xo\n",
    "    \n",
    "    ## ===== activators\n",
    "    @staticmethod \n",
    "    def relu(x):\n",
    "        return max(0,x)\n",
    "    @staticmethod\n",
    "    def sfunc(x):\n",
    "        #return  (1 + np.exp(x))/(np.exp(x).sum())\n",
    "        return (x - (-1))/(1 - (-1))*x\n",
    "    \n",
    "    ## ===== output dists\n",
    "    @staticmethod\n",
    "    def softmax(inz_arr):\n",
    "        pz = np.exp(inz_arr) \n",
    "        #print(pz.shape)\n",
    "        pxs = (pz)/np.sum(pz)\n",
    "        return pxs\n",
    "        \n",
    "    ## ===== losses\n",
    "    @staticmethod\n",
    "    def hinge_loss(y, yhat, thresh=1e-06, margin=0.15):\n",
    "        d = np.abs(y-yhat) + margin  > thresh\n",
    "        #print(d, np.abs(y-yhat), thresh)\n",
    "        return int( d )\n",
    "    @staticmethod\n",
    "    def mse_loss(y, yhat):\n",
    "        return np.linalg.norm(np.array(y)  - np.array(yhat) )**2\n",
    "    \n",
    "class Node:\n",
    "    def __init__(self, in_weights, agg_func, act_func, bias=0):\n",
    "        self.in_weights = in_weights\n",
    "        self.in_bias = bias\n",
    "        self.agg_func = agg_func\n",
    "        self.act_func = act_func\n",
    "        self.value = 0\n",
    "        \n",
    "    ## TODO: clean up the calls :/!! AND adjacency/one-hot on input layer??\n",
    "    def fwd_pass(self, X):\n",
    "        if self.agg_func is None:\n",
    "            self.value = X\n",
    "        elif self.act_func is None:\n",
    "            self.value = self.agg_func(X, self.in_weights, self.in_bias )\n",
    "        else:\n",
    "            self.value = self.act_func( self.agg_func(X, self.in_weights, self.in_bias ) )\n",
    "        return self.value \n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"{round(self.value,4)}\" #{len(self.in_weights)}-->\n",
    "    \n",
    "    \n",
    "class Layer:\n",
    "    def __init__(self, n_nodes, n_incoming, \n",
    "                 agg_func=None, act_func=None, \n",
    "                 weights_0=None, bias_0=None,\n",
    "                 isInput=False, isSharedWeights=True): \n",
    "        self.isInput = isInput\n",
    "        \n",
    "        #print(n_nodes, n_incoming,  0.1 * np.random.randn(n_incoming))\n",
    "        ## setup weights \n",
    "        if self.isInput:\n",
    "            weights = np.eye(n_nodes) #np.array([1])\n",
    "        else: \n",
    "            if weights_0 is not None:\n",
    "                weights = weights_0 \n",
    "            else:\n",
    "                if isSharedWeights:\n",
    "                    w = 0.1 * np.random.randn(n_incoming)\n",
    "                    weights = [w for i in range(n_nodes)] \n",
    "                else:\n",
    "                    weights = [ 0.1 * np.random.randn(n_incoming) for i in range(n_nodes) ]  \n",
    "            weights = np.array(weights) \n",
    "        bias=np.zeros(n_nodes) if bias_0 is None else bias_0\n",
    "        \n",
    "        ## setup nodes\n",
    "        #print(weights.shape, bias.shape)\n",
    "        self.nodes =np.array([ Node(weights[i], agg_func, act_func, bias=bias[i]) for i in range(n_nodes) ] )\n",
    "        \n",
    "    def fwd_pass(self, X):\n",
    "        return np.array([n.fwd_pass(X) for n in self.nodes])\n",
    "    \n",
    "    ## TODO: fix who holds this + backprop exec \n",
    "    def update_weights(self, weights, biases): \n",
    "        for i, n in enumerate(self.nodes):\n",
    "            n.in_weights = weights[i]\n",
    "            n.in_bias = biases[i]\n",
    "    \n",
    "    @property\n",
    "    def n_outputs(self):\n",
    "        return len(self.nodes)\n",
    "    @property\n",
    "    def weights(self): \n",
    "        return [ (n.in_weights, n.in_bias) for n in self.nodes]\n",
    "    \n",
    "    def __str__(self):\n",
    "        s = [f\"n={len(self.nodes)}: \"]\n",
    "        for n in self.nodes:\n",
    "            s.append(f\"[{str(n)}]\")            \n",
    "        return \", \".join(s)\n",
    "        \n",
    "class Network:\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs, \n",
    "                 w_hidden=3, isSharedWeights=False,\n",
    "                 agg_func=FUtilz.linear, act_func=FUtilz.relu, \n",
    "                 out_func=FUtilz.sfunc): \n",
    "        \n",
    "        self.inlayer = Layer( n_inputs, 1, isInput=True, \n",
    "                             agg_func=agg_func, act_func=FUtilz.identity)\n",
    "        \n",
    "        #self.hiddenlayers = [Layer(w_hidden, n_inputs,  agg_func=agg_func, act_func=act_func,isSharedWeights=isSharedWeights) for i in range(n_hidden)]\n",
    "        self.hiddenlayers = []\n",
    "        for i in range(n_hidden):\n",
    "            n = self.hiddenlayers[i-1].n_outputs if i > 0 else n_inputs \n",
    "            self.hiddenlayers.append( Layer(w_hidden, n, \n",
    "                                   agg_func=agg_func, act_func=act_func,\n",
    "                                   isSharedWeights=isSharedWeights) )\n",
    "            \n",
    "        self.outlayer = Layer(n_outputs,  self.hiddenlayers[-1].n_outputs, \n",
    "                              agg_func=agg_func, act_func=out_func)\n",
    "        \n",
    "        self.predz = None\n",
    "        \n",
    "    ## TODO: output layer maps per node @ fwd and backprop\n",
    "    def fwd_pass(self, X):\n",
    "        ### --- FNN ---\n",
    "        ## 1. agg and activate \n",
    "        x = self.inlayer.fwd_pass(X)\n",
    "        for h in self.hiddenlayers:\n",
    "            x = h.fwd_pass(x)\n",
    "        x = self.outlayer.fwd_pass(x)\n",
    "        ## 2. pdf\n",
    "        self.predz = FUtilz.softmax(x)\n",
    "        return self.predz\n",
    "    \n",
    "    def propagate(self, predz, yz):\n",
    "        ## 3. loss\n",
    "        loss = FUtilz.mse_loss(yz, predz)\n",
    "        #print(\"\\n-----\\nLOSS: \", loss, \"<< \", np.round(predz, 3), yz, \"\\n-----\\n\")\n",
    "        ## 4. gd backprop             \n",
    "        ## 5. update weights per layer  \n",
    "        ## FAKING IT FOR NOW\n",
    "        def update_weights(h, ploss):\n",
    "            #print(h.weights)\n",
    "            #w, b = h.weights ### arrrgggg\n",
    "            W, B = [], []\n",
    "            for w, b in h.weights:\n",
    "                r = 0.01 * np.random.rand() \n",
    "                b +=  -(ploss.sum() / w.sum()**2)*r \n",
    "                if ploss.sum() <= w.mean():\n",
    "                    w = (w - ploss.sum()/w.max())*r\n",
    "                w += ((w/w.sum()) + (w/w.max()))*r/w.sum()\n",
    "                W.append(w)\n",
    "                B.append(b)\n",
    "            h.update_weights(W, B)\n",
    "            return np.array(W)\n",
    "            \n",
    "        fkl = update_weights(self.outlayer, loss)\n",
    "        for i in reversed( range(len(self.hiddenlayers)) ):\n",
    "            fkl = update_weights( self.hiddenlayers[i], fkl)  \n",
    "        \n",
    "        w = [f\"\\t{i}\" for i in self.outlayer.weights]\n",
    "        w = \"\\n\".join(w)\n",
    "        return loss, w\n",
    "        \n",
    "    def __str__(self): \n",
    "        l = [ f\"I: {str(self.inlayer)}\"]\n",
    "        for i, h in enumerate(self.hiddenlayers):\n",
    "            l.append( f\"H{(i+1)}: {str(h)}\")\n",
    "        l.append(f\"O:  {str(self.outlayer)}\")\n",
    "        \n",
    "        pz = np.round(self.predz, 4) if self.predz is not None else self.predz\n",
    "        l.append(f\"Px: {str(pz) }\" )\n",
    "        \n",
    "        w = [f\"\\t{i}\" for i in self.outlayer.weights]\n",
    "        w = \"\\n\".join(w)\n",
    "        l.append(f\"Wo: {(w)}\")\n",
    "        \n",
    "        return \"\\n\".join(l)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 1.0\n",
      "Epoch 2/20: 1.0\n",
      "Epoch 3/20: 1.0\n",
      "Epoch 4/20: 1.0\n",
      "Epoch 5/20: 1.0\n",
      "Epoch 6/20: 1.0\n",
      "Epoch 7/20: 1.0\n",
      "Epoch 8/20: 1.0\n",
      "Epoch 9/20: 1.0\n",
      "Epoch 10/20: 1.0\n",
      "Epoch 11/20: 1.0\n",
      "Epoch 12/20: 1.0\n",
      "Epoch 13/20: 1.0\n",
      "Epoch 14/20: 1.0\n",
      "Epoch 15/20: 1.0\n",
      "Epoch 16/20: 1.0\n",
      "Epoch 17/20: 1.0\n",
      "Epoch 18/20: 1.0\n",
      "Epoch 19/20: 1.0\n",
      "Epoch 20/20: 1.0\n",
      "\n",
      "\n",
      " I: n=7: , [7.9895], [4.2917], [-9.2724], [-0.0503], [3.728], [-4.3205], [1.5931]\n",
      "H1: n=3: , [0.2799], [0.3681], [0.3199]\n",
      "H2: n=3: , [0], [0], [0]\n",
      "O:  n=3: , [-0.09], [-0.1011], [-0.0937]\n",
      "Px: [0.335  0.3313 0.3337]\n",
      "Wo: \t(array([ 0.51841654, -0.17360098,  0.38198392]), -0.7694898890544014)\n",
      "\t(array([ 0.51561871, -0.17266408,  0.3799224 ]), -0.7377521972650453)\n",
      "\t(array([ 0.51643337, -0.17293688,  0.38052267]), -0.7591455926252884)\n",
      "FIN: p --> y [0 0 0]  -->  [0 1 0]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "OK_THRESH = 0.37\n",
    "N_OUTS = 3\n",
    "N_INS = 7\n",
    "EPOCHS = 20\n",
    "\n",
    "X = np.random.randn(N_INS)*np.random.randint(10)\n",
    "y = np.random.randint(0,2, size=N_OUTS)\n",
    "\n",
    "def train_something(tX, ty, n_hidden, n_outs=N_OUTS, w_hidden=3, isSharedWeights=False): \n",
    "    net = Network(len(tX), n_hidden, n_outs, w_hidden=w_hidden, isSharedWeights=isSharedWeights)\n",
    "    #print(net)\n",
    "    #net.propagate(net.fwd_pass(X), y)\n",
    "    for i in range(EPOCHS):\n",
    "        outz = net.fwd_pass(X)\n",
    "        predz = np.array(np.array(outz) > OK_THRESH, dtype=int)\n",
    "        loss, w = net.propagate(predz, y) \n",
    "        print(f\"Epoch {(i+1)}/{EPOCHS}: {loss}\") #\\n{w}\n",
    "        if loss <= 1e-05:\n",
    "            break\n",
    "\n",
    "    print(\"\\n\\n\",net)\n",
    "    print(\"FIN: p --> y\", predz, \" --> \", y)\n",
    "\n",
    "train_something(X,y, n_hidden=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 1.0\n",
      "Epoch 2/20: 1.0\n",
      "Epoch 3/20: 1.0\n",
      "Epoch 4/20: 1.0\n",
      "Epoch 5/20: 1.0\n",
      "Epoch 6/20: 1.0\n",
      "Epoch 7/20: 1.0\n",
      "Epoch 8/20: 1.0\n",
      "Epoch 9/20: 1.0\n",
      "Epoch 10/20: 1.0\n",
      "Epoch 11/20: 2.0000000000000004\n",
      "Epoch 12/20: 2.0000000000000004\n",
      "Epoch 13/20: 2.0000000000000004\n",
      "Epoch 14/20: 1.0\n",
      "Epoch 15/20: 1.0\n",
      "Epoch 16/20: 1.0\n",
      "Epoch 17/20: 1.0\n",
      "Epoch 18/20: 1.0\n",
      "Epoch 19/20: 1.0\n",
      "Epoch 20/20: 1.0\n",
      "\n",
      "\n",
      " I: n=7: , [7.9895], [4.2917], [-9.2724], [-0.0503], [3.728], [-4.3205], [1.5931]\n",
      "H1: n=3: , [0], [1.2237], [0]\n",
      "H2: n=3: , [14.6866], [126.3177], [0]\n",
      "H3: n=3: , [0], [30204.186], [0]\n",
      "H4: n=3: , [68803.287], [10487.1033], [0]\n",
      "H5: n=3: , [0], [9369.9039], [0]\n",
      "H6: n=3: , [0], [163.6912], [2616.6929]\n",
      "O:  n=3: , [3778.458], [3268.4227], [4212.848]\n",
      "Px: [nan nan nan]\n",
      "Wo: \t(array([0.43006021, 0.25130627, 0.01797112]), -0.6019875106320232)\n",
      "\t(array([0.41322876, 0.24147079, 0.01726778]), -0.6074435260165008)\n",
      "\t(array([0.4632241 , 0.27068563, 0.01935695]), -0.6656433235088529)\n",
      "FIN: p --> y [0 0 0]  -->  [0 1 0]\n"
     ]
    }
   ],
   "source": [
    "train_something(X, y, n_hidden=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
