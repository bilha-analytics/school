{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "\n",
    "- Human Perception Vs machine usage \n",
    "- systematic analysis and evaluation\n",
    "    - qualitative Vs quantitative\n",
    "        - Qualitative: subjective, linkert scales \n",
    "        - Quantitative: objective, loss functions (MSE usually)\n",
    "    - reproducability \n",
    "        - record and report processing actions \n",
    "        - apply similar treatments to control gorups \n",
    "  \n",
    "\n",
    "**Digital Vs Analog signal**\n",
    "- Conversion: From Analog to Digital. \n",
    "    - Sampling: on (x,y) coordinates\n",
    "    - Quantization on f(x,y) values \n",
    "    - Discretize \n",
    "    \n",
    "- Signal processing approaches\n",
    "\n",
    "\n",
    "**Three General Phases of Analysis**\n",
    "1. Preprocessing\n",
    "    - Acquisition, sampling, quantization \n",
    "    - output: image \n",
    "\n",
    "\n",
    "2. Enchancement and Display\n",
    "    - filtering, enhancement, restoration, \n",
    "    - color processing, wavelets transforms, compression, watermarking, morphological processing, \n",
    "    - output: image \n",
    "\n",
    "\n",
    "3. Information Extraction \n",
    "    - morphological processing, segmentation, feature extraction, image pattern classification \n",
    "    - output: image attributes - \n",
    "\n",
    "\n",
    "Formats \n",
    "- Image input/output: color/gray, unit\n",
    "- Image processing: gray or channel by channel, float,\n",
    "\n",
    "\n",
    "**References and Credits** \n",
    "- Images are as per source\n",
    "- for this collection [Ref BPNani on github](https://github.com/BhanuPrakashNani/Image_Processing). He references [Digital Image Processing book by Gonzalez et al](https://www.amazon.com/Digital-Image-Processing-Rafael-Gonzalez/dp/0133356728) \n",
    "![](https://images-na.ssl-images-amazon.com/images/I/41blrfp3aXL._SX400_BO1,204,203,200_.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concepts\n",
    "**Averaging Images:**\n",
    "- Basic image enhancement technique of a set of related images using arithmetic mean\n",
    "\n",
    "**Interpolation:** \n",
    "- is an approximation method and so successive operations lose information and may degrade image quality. So reduce the number of operations. E.g. rotating 45 degrees 8 times degrades quality compared to 90 degrees 4 times\n",
    "    \n",
    "    - Tasks: zooming, shrinking, rotating, geometric corrections \n",
    "\n",
    "    - It uses known data to estimate unknown locations and their values \n",
    "\n",
    "    - Techniques: nearest neighbour, bilinear, bicubic\n",
    "        - bicubic uses higher-oder equation and so can capture features in-depth?? \n",
    "        \n",
    "**Interpolation-Inverse Mapping:** \n",
    "- Two methods of mapping:\n",
    "    - Forward mapping: original --to--> transformed, pixel-wise, interpolation \n",
    "    - Reverse mapping: transformed --to--> original, pixel wise, sampling,  \n",
    "    \n",
    "    \n",
    "**Categories of operations:** \n",
    "1. Linear transforms: rotation, scaling, shear, translation  \n",
    "    - linear operations \n",
    "2. Non-linear transforms:\n",
    "    - \n",
    "3. Morphological: \n",
    "    - Based on image topography - shape, \n",
    "    \n",
    "## Enhancement Techniques\n",
    "**Perspective Transformation**:- make corrections to skewed/sheared distortions. reset coordinate system to (i,j) basis \n",
    "\n",
    "**Histogram-based Transformations**: Global operation, or hood-level. Correct contrast by normalizing intesity values to some target range/distribution.  Uniform distribution is often the target distribution. \n",
    "- How: Operates on the CDF. Normalized image as $\\mu = 0$ and $\\sigma^2 = 1$. Normalization is often used to increase contrast and remove noise. Sets up image for further processing.\n",
    "\n",
    "- Log transform: $out_{pixel} = c * log(in_{pixel} + 1)$, c is a constant. A gray-level transformation \n",
    "\n",
    "- Contrast Stretching: Stretches range of intensity values to span a desired range. High and low intensity values (by a given percentile threshold) get pulled to the boundaries of this desired range. Has softer more visually appealing results - better for human use than machine use. \n",
    "\n",
    "- Histogram Equilization: normalizes histogram to a target distribution, often the uniform distribution. Is global operation.\n",
    "\n",
    "- Adaptive equilization: Same as histogram equilization only that it operates  at a hood-level. More susceptible to noise. Better at finding foreground objects or enhancing edges. \n",
    "\n",
    "**Denoising/Blurring Enhancement** \n",
    "Noise: camera light obstruction, glare, \n",
    "Operations: convolution TODO: compare correlation \n",
    "- Gaussian Blur: \n",
    "- Median blur:\n",
    "- Box Filter: average filter \n",
    "- \n",
    " \n",
    "**Sharpenning/Edge Enhancement**\n",
    "Operations: Convolution, \n",
    "- Laplacian: \n",
    "    - Second derivative of an image - rate at which intensity values are changing and so more change/contrast suggests an edge \n",
    "    - Very sensitive to noise. Can also produce double edges depending on threshold value\n",
    "    - Example kernel: \n",
    "    - +Gaussian: combine with gaussian to denoise first and reduce sensitivity to noise. The larger the gaussian kernel the more the smoothing, the less the sensitivity to noise but watch out not to loose desired information\n",
    "    - *When to use:* Location of edges \n",
    "\n",
    "- Sobel:\n",
    "    - First derivative, \n",
    "    - two directions: X, Y, \n",
    "    - Pad the image first to preserve any features at the edges of the image. \n",
    "    - *When to use:* Direction of edges\n",
    "\n",
    "- Canny Edge:\n",
    "    - Multi-stage algorithm, that combines denoising, edge detection and hysteresis  \n",
    "    - Noise Reduction: Gaussian filter to denoise. Usually 5x5 filter\n",
    "    - Intensity Gradient: Sobel first derivatives in both X, Y directions. Combine the two gradients (pythagoras-like or angle between them)\n",
    "    - Non-maximum Suppression: Remove pixels that don't constitute an edge, if a pixel is below local maximum in the given direction of the gradient \n",
    "    - Hysteresis thresholding: Make edges as thin as possible - 1pix - and Make continuous. Threshold values for max and min. Discard what's below min and set sure-edges to pixels above max. For pixels in between, discard if not connected to a sure-edge \n",
    "\n",
    "## Morphological Processing \n",
    "**Transformations**\n",
    "Operate on binary images?\n",
    "- Erosion:  \n",
    "- Dilation: Opposite of erosion.  \n",
    "- Opening: Erode then dilate \n",
    "- Closing: Dilate then erode \n",
    "- Morphological gradient: Dilated - eroded img = outline of object \n",
    "\n",
    "\n",
    "Applications\n",
    "- text processing \n",
    "- fingerprint processing \n",
    "- \n",
    "\n",
    "## Color Processing \n",
    "\n",
    "**Image Temperature**\n",
    "- \n",
    "\n",
    "## Video Processing \n",
    "Uses\n",
    "- video background substraction \n",
    "- \n",
    "\n",
    "## Other Stuff\n",
    "**Countours:** A collection of curves that join all the continuos points along the boundary of an object AND that have similar characteristics such as intensity, color, \n",
    "- Uses: object identification, object shape analysis. \n",
    "\n",
    "**Fitting Polygons:** \n",
    "\n",
    "**Hough Line Transform:** \n",
    "- Uses: to detect straight lines \n",
    "\n",
    "**Thresholding Methods** Turning images into binary images. Different ways to choose the threshold. \n",
    "- Gaussian and Adaptive Gaussian: At global Vs hood level \n",
    "- OTSU: Is global. Uses histogram to choose threshold. Searc process entails first segmenting using histogram and then  maximizing intra-class variance of segments, which is same as  minimising interclass variance in OTSU and more computationally efficient. \n",
    "\n",
    "\n",
    "**Foreground/Background extraction Methods**\n",
    "- **Grabcut:** \n",
    "    - foreground extraction with minimal userinteraction \n",
    "    - Steps: user draws rectangle around foreground region then alg iteratively segments the image to seperate the object \n",
    "    \n",
    "    \n",
    "## Discrete Fourier Transform\n",
    "Fourier Transform (FT) --> any function can be approximated with the sum of infinite sines and cosines in the fq domain.\n",
    "- $\\int e^{-i 2 \\pi x}$ and $e^{i x} = cos x + i \\; sin x$\n",
    "- For discrete case, operator is sum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_transform(img):\n",
    "    def ft(pixel):\n",
    "        return pixel * np."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
